{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: gym-anytrading in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: gym-trading-env in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: stable-baselines3 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym) (1.26.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-anytrading) (2.1.2)\n",
      "Requirement already satisfied: gymnasium>=0.29.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-anytrading) (0.29.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-anytrading) (3.8.1)\n",
      "Requirement already satisfied: ccxt==3.0.59 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-trading-env) (3.0.59)\n",
      "Requirement already satisfied: nest-asyncio in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-trading-env) (1.5.8)\n",
      "Requirement already satisfied: flask>=2.2.3 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-trading-env) (3.0.0)\n",
      "Requirement already satisfied: pyecharts>=2.0.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gym-trading-env) (2.0.4)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (2.31.0)\n",
      "Requirement already satisfied: cryptography>=2.6.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (41.0.5)\n",
      "Requirement already satisfied: aiodns>=1.1.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (3.1.1)\n",
      "Requirement already satisfied: yarl>=1.7.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (1.9.2)\n",
      "Requirement already satisfied: setuptools>=60.9.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (65.5.0)\n",
      "Requirement already satisfied: aiohttp>=3.8 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (3.8.6)\n",
      "Requirement already satisfied: certifi>=2018.1.18 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from ccxt==3.0.59->gym-trading-env) (2023.7.22)\n",
      "Requirement already satisfied: torch>=1.13 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from stable-baselines3) (2.1.1)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (1.7.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from flask>=2.2.3->gym-trading-env) (3.1.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gymnasium>=0.29.1->gym-anytrading) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from gymnasium>=0.29.1->gym-anytrading) (4.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (4.44.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (10.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from matplotlib>=3.1.1->gym-anytrading) (3.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from pandas>=0.24.2->gym-anytrading) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from pandas>=0.24.2->gym-anytrading) (2023.3.post1)\n",
      "Requirement already satisfied: prettytable in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from pyecharts>=2.0.2->gym-trading-env) (3.9.0)\n",
      "Requirement already satisfied: simplejson in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from pyecharts>=2.0.2->gym-trading-env) (3.19.2)\n",
      "Requirement already satisfied: networkx in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (1.12)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (2023.12.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3) (12.3.101)\n",
      "Requirement already satisfied: pycares>=4.0.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiodns>=1.1.1->ccxt==3.0.59->gym-trading-env) (4.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (3.3.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from aiohttp>=3.8->ccxt==3.0.59->gym-trading-env) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from cryptography>=2.6.1->ccxt==3.0.59->gym-trading-env) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=2.2.3->gym-trading-env) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->gym-anytrading) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from requests>=2.18.4->ccxt==3.0.59->gym-trading-env) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from requests>=2.18.4->ccxt==3.0.59->gym-trading-env) (2.0.7)\n",
      "Requirement already satisfied: wcwidth in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from prettytable->pyecharts>=2.0.2->gym-trading-env) (0.2.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt==3.0.59->gym-trading-env) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym gym-anytrading gym-trading-env stable-baselines3\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "# do not remove!\n",
    "from gym_trading_env.environments import TradingEnv\n",
    "from gym_trading_env.renderer import Renderer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas._libs.tslibs.timestamps import Timestamp\n",
    "\n",
    "##\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from coin_data import get_coin_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement gym-trading env\n",
    "https://gym-trading-env.readthedocs.io/en/latest/rl_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UserWarning",
     "evalue": "CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserWarning\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m coin_data \u001b[39m=\u001b[39m preprocess_data(data, window_size\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m env \u001b[39m=\u001b[39m get_env(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mBTC/USDT\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     coin_data, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     window_size\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     positions\u001b[39m=\u001b[39m[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.75\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.25\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0.25\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.75\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m DQN(\u001b[39m'\u001b[39;49m\u001b[39mMlpPolicy\u001b[39;49m\u001b[39m'\u001b[39;49m, env, learning_starts\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, tau\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m, exploration_initial_eps\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, exploration_fraction\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, exploration_final_eps\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train_model(\u001b[39m'\u001b[39m\u001b[39mDQN\u001b[39m\u001b[39m'\u001b[39m, model, env, \u001b[39m1e5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pahautelman/Projects/bitcoin-bot/bitcoin-bot/agents/rl_agent/playground.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m eval_model(\u001b[39m'\u001b[39m\u001b[39mDQN\u001b[39m\u001b[39m'\u001b[39m, model, env, coin_data, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py:104\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m     policy: Union[\u001b[39mstr\u001b[39m, Type[DQNPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _init_setup_model: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    103\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    105\u001b[0m         policy,\n\u001b[1;32m    106\u001b[0m         env,\n\u001b[1;32m    107\u001b[0m         learning_rate,\n\u001b[1;32m    108\u001b[0m         buffer_size,\n\u001b[1;32m    109\u001b[0m         learning_starts,\n\u001b[1;32m    110\u001b[0m         batch_size,\n\u001b[1;32m    111\u001b[0m         tau,\n\u001b[1;32m    112\u001b[0m         gamma,\n\u001b[1;32m    113\u001b[0m         train_freq,\n\u001b[1;32m    114\u001b[0m         gradient_steps,\n\u001b[1;32m    115\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,  \u001b[39m# No action noise\u001b[39;49;00m\n\u001b[1;32m    116\u001b[0m         replay_buffer_class\u001b[39m=\u001b[39;49mreplay_buffer_class,\n\u001b[1;32m    117\u001b[0m         replay_buffer_kwargs\u001b[39m=\u001b[39;49mreplay_buffer_kwargs,\n\u001b[1;32m    118\u001b[0m         policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs,\n\u001b[1;32m    119\u001b[0m         stats_window_size\u001b[39m=\u001b[39;49mstats_window_size,\n\u001b[1;32m    120\u001b[0m         tensorboard_log\u001b[39m=\u001b[39;49mtensorboard_log,\n\u001b[1;32m    121\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    122\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    123\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    124\u001b[0m         sde_support\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    125\u001b[0m         optimize_memory_usage\u001b[39m=\u001b[39;49moptimize_memory_usage,\n\u001b[1;32m    126\u001b[0m         supported_action_spaces\u001b[39m=\u001b[39;49m(spaces\u001b[39m.\u001b[39;49mDiscrete,),\n\u001b[1;32m    127\u001b[0m         support_multi_env\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexploration_initial_eps \u001b[39m=\u001b[39m exploration_initial_eps\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexploration_final_eps \u001b[39m=\u001b[39m exploration_final_eps\n",
      "File \u001b[0;32m~/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:110\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     policy: Union[\u001b[39mstr\u001b[39m, Type[BasePolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[39m.\u001b[39mSpace], \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ):\n\u001b[0;32m--> 110\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    111\u001b[0m         policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[1;32m    112\u001b[0m         env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m    113\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    114\u001b[0m         policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs,\n\u001b[1;32m    115\u001b[0m         stats_window_size\u001b[39m=\u001b[39;49mstats_window_size,\n\u001b[1;32m    116\u001b[0m         tensorboard_log\u001b[39m=\u001b[39;49mtensorboard_log,\n\u001b[1;32m    117\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    118\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    119\u001b[0m         support_multi_env\u001b[39m=\u001b[39;49msupport_multi_env,\n\u001b[1;32m    120\u001b[0m         monitor_wrapper\u001b[39m=\u001b[39;49mmonitor_wrapper,\n\u001b[1;32m    121\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    122\u001b[0m         use_sde\u001b[39m=\u001b[39;49muse_sde,\n\u001b[1;32m    123\u001b[0m         sde_sample_freq\u001b[39m=\u001b[39;49msde_sample_freq,\n\u001b[1;32m    124\u001b[0m         supported_action_spaces\u001b[39m=\u001b[39;49msupported_action_spaces,\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_size \u001b[39m=\u001b[39m buffer_size\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m batch_size\n",
      "File \u001b[0;32m~/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:127\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_class \u001b[39m=\u001b[39m policy\n\u001b[0;32m--> 127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m get_device(device)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    129\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m device\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages/stable_baselines3/common/utils.py:154\u001b[0m, in \u001b[0;36mget_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    151\u001b[0m device \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mdevice(device)\n\u001b[1;32m    153\u001b[0m \u001b[39m# Cuda not available\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m th\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtype \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m th\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available():\n\u001b[1;32m    155\u001b[0m     \u001b[39mreturn\u001b[39;00m th\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m device\n",
      "File \u001b[0;32m~/Projects/bitcoin-bot/bitcoin-bot/bitcoinbot/lib/python3.10/site-packages/torch/cuda/__init__.py:138\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39mreturn\u001b[39;00m device_count() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[39m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[39m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39m# API via `cuInit`\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_getDeviceCount() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mUserWarning\u001b[0m: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)"
     ]
    }
   ],
   "source": [
    "from agents.rl_agent.util import eval_model, get_env, preprocess_data, train_model\n",
    "\n",
    "\n",
    "data = get_coin_data('BTC/USDT', '1h', start_date=Timestamp('2021-01-01'))\n",
    "\n",
    "coin_data = preprocess_data(data, window_size=60)\n",
    "\n",
    "env = get_env(\n",
    "    'BTC/USDT', \n",
    "    coin_data, \n",
    "    window_size=60, \n",
    "    positions=[-3, -2, -1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1, 2, 3],\n",
    ")\n",
    "model = DQN('MlpPolicy', env, learning_starts=100, verbose=1, tau=0.9, exploration_initial_eps=0.5, exploration_fraction=0.1, exploration_final_eps=0.05)\n",
    "train_model('DQN', model, env, 1e5)\n",
    "\n",
    "eval_model('DQN', model, env, coin_data, True)\n",
    "# data.rename(columns={\n",
    "#     'Open': 'open',\n",
    "#     'High': 'high',\n",
    "#     'Low': 'low',\n",
    "#     'Close': 'close',\n",
    "#     'Volume': 'volume'\n",
    "# }, inplace=True)\n",
    "# data.sort_index(inplace=True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(coin_data: DataFrame, window_size: int = 60) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Method preprocesses the coin data.\n",
    "    It normalizes the columns and drops the NaNs.\n",
    "\n",
    "    Columns \n",
    "        * 'Open': divide by 'Close'\n",
    "        * 'High': divide by 'Close'\n",
    "        * 'Low': divide by 'Close'\n",
    "        * 'Close': pct_change()\n",
    "        * 'Volume': divide by rolling 10-day max\n",
    "\n",
    "    :param data: DataFrame with coin data\n",
    "    :return: preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    coin_data[\"feature_Close\"] = coin_data[\"close\"].pct_change()\n",
    "    coin_data[\"feature_High\"] = coin_data[\"high\"] / coin_data[\"close\"]\n",
    "    coin_data[\"feature_Low\"] = coin_data[\"low\"] / coin_data[\"close\"]\n",
    "    coin_data[\"feature_Open\"] = coin_data[\"open\"] / coin_data[\"close\"]\n",
    "    coin_data[\"feature_Volume\"] = coin_data[\"volume\"] / coin_data[\"volume\"].rolling(window_size).max()\n",
    "\n",
    "    coin_data.dropna(inplace=True)\n",
    "    return coin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>feature_Close</th>\n",
       "      <th>feature_High</th>\n",
       "      <th>feature_Low</th>\n",
       "      <th>feature_Open</th>\n",
       "      <th>feature_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-03 11:00:00</th>\n",
       "      <td>33877.96</td>\n",
       "      <td>34450.00</td>\n",
       "      <td>33787.55</td>\n",
       "      <td>34413.53</td>\n",
       "      <td>4116.853141</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>1.001060</td>\n",
       "      <td>0.981810</td>\n",
       "      <td>0.984437</td>\n",
       "      <td>0.261665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03 12:00:00</th>\n",
       "      <td>34413.53</td>\n",
       "      <td>34600.00</td>\n",
       "      <td>33928.75</td>\n",
       "      <td>34103.72</td>\n",
       "      <td>4546.283481</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>1.014552</td>\n",
       "      <td>0.994869</td>\n",
       "      <td>1.009084</td>\n",
       "      <td>0.288960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03 13:00:00</th>\n",
       "      <td>34103.73</td>\n",
       "      <td>34385.02</td>\n",
       "      <td>33800.00</td>\n",
       "      <td>33880.00</td>\n",
       "      <td>4373.738376</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>1.014906</td>\n",
       "      <td>0.997639</td>\n",
       "      <td>1.006604</td>\n",
       "      <td>0.277993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03 14:00:00</th>\n",
       "      <td>33877.98</td>\n",
       "      <td>34150.00</td>\n",
       "      <td>33450.00</td>\n",
       "      <td>33811.54</td>\n",
       "      <td>5928.805563</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>1.010010</td>\n",
       "      <td>0.989307</td>\n",
       "      <td>1.001965</td>\n",
       "      <td>0.376832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03 15:00:00</th>\n",
       "      <td>33811.54</td>\n",
       "      <td>33873.45</td>\n",
       "      <td>32727.00</td>\n",
       "      <td>33506.62</td>\n",
       "      <td>8391.249757</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>1.010948</td>\n",
       "      <td>0.976732</td>\n",
       "      <td>1.009100</td>\n",
       "      <td>0.533344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-12 18:00:00</th>\n",
       "      <td>40702.99</td>\n",
       "      <td>41421.14</td>\n",
       "      <td>40680.00</td>\n",
       "      <td>41305.44</td>\n",
       "      <td>2334.042350</td>\n",
       "      <td>0.014801</td>\n",
       "      <td>1.002801</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.985415</td>\n",
       "      <td>0.215786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-12 19:00:00</th>\n",
       "      <td>41305.44</td>\n",
       "      <td>41330.00</td>\n",
       "      <td>41025.00</td>\n",
       "      <td>41137.99</td>\n",
       "      <td>1268.109820</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>1.004667</td>\n",
       "      <td>0.997253</td>\n",
       "      <td>1.004070</td>\n",
       "      <td>0.117239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-12 20:00:00</th>\n",
       "      <td>41137.99</td>\n",
       "      <td>41294.00</td>\n",
       "      <td>41063.18</td>\n",
       "      <td>41229.61</td>\n",
       "      <td>1111.426630</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>1.001562</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>0.102753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-12 21:00:00</th>\n",
       "      <td>41229.61</td>\n",
       "      <td>41381.10</td>\n",
       "      <td>41042.08</td>\n",
       "      <td>41104.02</td>\n",
       "      <td>1216.505640</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>1.006741</td>\n",
       "      <td>0.998493</td>\n",
       "      <td>1.003055</td>\n",
       "      <td>0.112468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-12 22:00:00</th>\n",
       "      <td>41104.02</td>\n",
       "      <td>41220.38</td>\n",
       "      <td>41079.48</td>\n",
       "      <td>41216.95</td>\n",
       "      <td>665.072740</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>1.000083</td>\n",
       "      <td>0.996665</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.061487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25750 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close       volume  \\\n",
       "Timestamp                                                                  \n",
       "2021-01-03 11:00:00  33877.96  34450.00  33787.55  34413.53  4116.853141   \n",
       "2021-01-03 12:00:00  34413.53  34600.00  33928.75  34103.72  4546.283481   \n",
       "2021-01-03 13:00:00  34103.73  34385.02  33800.00  33880.00  4373.738376   \n",
       "2021-01-03 14:00:00  33877.98  34150.00  33450.00  33811.54  5928.805563   \n",
       "2021-01-03 15:00:00  33811.54  33873.45  32727.00  33506.62  8391.249757   \n",
       "...                       ...       ...       ...       ...          ...   \n",
       "2023-12-12 18:00:00  40702.99  41421.14  40680.00  41305.44  2334.042350   \n",
       "2023-12-12 19:00:00  41305.44  41330.00  41025.00  41137.99  1268.109820   \n",
       "2023-12-12 20:00:00  41137.99  41294.00  41063.18  41229.61  1111.426630   \n",
       "2023-12-12 21:00:00  41229.61  41381.10  41042.08  41104.02  1216.505640   \n",
       "2023-12-12 22:00:00  41104.02  41220.38  41079.48  41216.95   665.072740   \n",
       "\n",
       "                     feature_Close  feature_High  feature_Low  feature_Open  \\\n",
       "Timestamp                                                                     \n",
       "2021-01-03 11:00:00       0.015809      1.001060     0.981810      0.984437   \n",
       "2021-01-03 12:00:00      -0.009003      1.014552     0.994869      1.009084   \n",
       "2021-01-03 13:00:00      -0.006560      1.014906     0.997639      1.006604   \n",
       "2021-01-03 14:00:00      -0.002021      1.010010     0.989307      1.001965   \n",
       "2021-01-03 15:00:00      -0.009018      1.010948     0.976732      1.009100   \n",
       "...                            ...           ...          ...           ...   \n",
       "2023-12-12 18:00:00       0.014801      1.002801     0.984858      0.985415   \n",
       "2023-12-12 19:00:00      -0.004054      1.004667     0.997253      1.004070   \n",
       "2023-12-12 20:00:00       0.002227      1.001562     0.995963      0.997778   \n",
       "2023-12-12 21:00:00      -0.003046      1.006741     0.998493      1.003055   \n",
       "2023-12-12 22:00:00       0.002747      1.000083     0.996665      0.997260   \n",
       "\n",
       "                     feature_Volume  \n",
       "Timestamp                            \n",
       "2021-01-03 11:00:00        0.261665  \n",
       "2021-01-03 12:00:00        0.288960  \n",
       "2021-01-03 13:00:00        0.277993  \n",
       "2021-01-03 14:00:00        0.376832  \n",
       "2021-01-03 15:00:00        0.533344  \n",
       "...                             ...  \n",
       "2023-12-12 18:00:00        0.215786  \n",
       "2023-12-12 19:00:00        0.117239  \n",
       "2023-12-12 20:00:00        0.102753  \n",
       "2023-12-12 21:00:00        0.112468  \n",
       "2023-12-12 22:00:00        0.061487  \n",
       "\n",
       "[25750 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_data = preprocess(data)\n",
    "coin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make reward funcition\n",
    "def reward_function(history):\n",
    "    return np.log(history[\"portfolio_valuation\", -1] / history[\"portfolio_valuation\", -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"TradingEnv\",\n",
    "    name=\"BTC/USD\",\n",
    "    df=coin_data,\n",
    "    windows=5,\n",
    "    positions=[-5, -4, -3, -2, -1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1, 2, 3, 4, 5],\n",
    "    trading_fees=0.001,\n",
    "    borrow_interest_rate=0.0003/100,  # 0.003% per timestamp (one timestamp = 1 hour)\n",
    "    reward_function=reward_function,\n",
    "    portfolio_initial_value=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 4, 'step': 0, 'date': numpy.datetime64('2021-01-03T15:00:00.000000000'), 'position_index': 11, 'position': 0.75, 'real_position': 0.75, 'data_high': 33873.45, 'data_open': 33811.54, 'data_volume': 8391.249757, 'data_close': 33506.62, 'data_low': 32727.0, 'portfolio_valuation': 1000.0, 'portfolio_distribution_asset': 0.02238363642766713, 'portfolio_distribution_fiat': 250.0, 'portfolio_distribution_borrowed_asset': 0, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0, 'portfolio_distribution_interest_fiat': 0, 'reward': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 24146   |   Episode Length : 25746   |   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "env.unwrapped.add_metric('Position Changes', lambda history : np.sum(np.diff(history['position']) != 0) )\n",
    "env.unwrapped.add_metric('Episode Length', lambda history : len(history['position']) )\n",
    "\n",
    "done, truncated = False, False\n",
    "observation, info = env.reset()\n",
    "print(info)\n",
    "while not done and not truncated:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "env.render()\n",
    "\n",
    "env.unwrapped.save_for_render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renderer = Renderer(render_logs_dir=\"render_logs/BTC\")\n",
    "# renderer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi Dataset Trading environment\n",
    "# TODO: add data from more exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- implement agent. No idea what the openAI network looks like\n",
    "- consider Random Forest model\n",
    "- consider XGBoost model\n",
    "- stacking multiple diverse models, and a meta model on top of that\n",
    "- observe copilot's demoralizing tips when it comes to trading 🤔🤔🤔 \n",
    "- consider RNN\n",
    "- feed the results of a time series model (ARIMA, GARCH) as input features for a machine learning model\n",
    "- Markov chain model\n",
    "- stop making fun of me, copilot! 🤬🤬🤬\n",
    "- consider LSTM model, https://sb3-contrib.readthedocs.io/en/master/modules/ppo_recurrent.html, https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Market Return : 23.01%   |   Portfolio Return : 11.45%   |   Position Changes : 1   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=100, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.108    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.455    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Market Return : 23.01%   |   Portfolio Return : 11.37%   |   Position Changes : 1   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=200, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.108    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.034    |\n",
      "|    n_updates        | 24       |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return :  9.66%   |   Position Changes : 2   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=300, episode_reward=0.09 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.0922   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 49       |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : 10.80%   |   Position Changes : 5   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=400, episode_reward=0.10 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.103    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 74       |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : 11.39%   |   Position Changes : 1   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=500, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.108    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 99       |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : 11.12%   |   Position Changes : 1   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=600, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.105    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.23     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 124      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : 11.45%   |   Position Changes : 1   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=700, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.108    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00896  |\n",
      "|    n_updates        | 149      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : 11.39%   |   Position Changes : 1   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=800, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | 0.108    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00668  |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -56.22%   |   Position Changes : 177   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=900, episode_reward=-0.83 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -0.826   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0955   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 199      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 10570   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1000, episode_reward=-25.32 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -25.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0505   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 224      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 19360   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1100, episode_reward=-61.47 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -61.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00549  |\n",
      "|    n_updates        | 249      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 16793   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1200, episode_reward=-38.34 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -38.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 23265   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1300, episode_reward=-93.02 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -93      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 299      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.64%   |   Position Changes : 211   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1400, episode_reward=-5.63 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -5.63    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 324      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -93.97%   |   Position Changes : 65   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1500, episode_reward=-2.81 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.81    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 349      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.89%   |   Position Changes : 127   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1600, episode_reward=-3.86 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.86    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -86.18%   |   Position Changes : 133   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1700, episode_reward=-1.98 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.98    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 399      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -81.46%   |   Position Changes : 82   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1800, episode_reward=-1.69 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.69    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 424      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -87.38%   |   Position Changes : 61   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=1900, episode_reward=-2.07 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.07    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 449      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -88.15%   |   Position Changes : 105   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2000, episode_reward=-2.13 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.13    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -96.01%   |   Position Changes : 124   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2100, episode_reward=-3.22 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.22    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 499      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -85.13%   |   Position Changes : 58   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2200, episode_reward=-1.91 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.91    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 524      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.08%   |   Position Changes : 96   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2300, episode_reward=-3.53 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.53    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 549      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.61%   |   Position Changes : 41   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2400, episode_reward=-2.92 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.92    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -95.83%   |   Position Changes : 33   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2500, episode_reward=-3.18 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.18    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000784 |\n",
      "|    n_updates        | 599      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -88.22%   |   Position Changes : 66   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2600, episode_reward=-2.14 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.14    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 624      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.96%   |   Position Changes : 85   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2700, episode_reward=-3.89 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.89    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 649      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -86.05%   |   Position Changes : 55   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2800, episode_reward=-1.97 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.97    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 674      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -90.68%   |   Position Changes : 47   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=2900, episode_reward=-2.37 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.37    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 699      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.93%   |   Position Changes : 150   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3000, episode_reward=-7.25 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -7.25    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 724      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -85.14%   |   Position Changes : 28   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3100, episode_reward=-1.91 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.91    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 749      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.05%   |   Position Changes : 35   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3200, episode_reward=-2.82 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.82    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 774      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -86.69%   |   Position Changes : 33   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3300, episode_reward=-2.02 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.02    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000955 |\n",
      "|    n_updates        | 799      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.93%   |   Position Changes : 29   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3400, episode_reward=-2.98 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.98    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 824      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -95.60%   |   Position Changes : 60   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3500, episode_reward=-3.12 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.12    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 849      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -92.37%   |   Position Changes : 31   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3600, episode_reward=-2.57 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.57    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -92.70%   |   Position Changes : 39   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3700, episode_reward=-2.62 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.62    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 899      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.52%   |   Position Changes : 46   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3800, episode_reward=-2.90 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 924      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -89.72%   |   Position Changes : 88   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=3900, episode_reward=-2.27 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.27    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 949      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -91.90%   |   Position Changes : 71   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4000, episode_reward=-2.51 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.51    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -87.99%   |   Position Changes : 52   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4100, episode_reward=-2.12 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.12    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 999      |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -91.45%   |   Position Changes : 50   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4200, episode_reward=-2.46 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.46    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 1024     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.31%   |   Position Changes : 45   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4300, episode_reward=-2.87 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.87    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1049     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -84.39%   |   Position Changes : 32   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4400, episode_reward=-1.86 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.86    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 1074     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -90.18%   |   Position Changes : 30   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4500, episode_reward=-2.32 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.32    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00059  |\n",
      "|    n_updates        | 1099     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.98%   |   Position Changes : 34   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4600, episode_reward=-2.99 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.99    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 1124     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.98%   |   Position Changes : 211   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4700, episode_reward=-8.50 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -8.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 1149     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.94%   |   Position Changes : 355   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4800, episode_reward=-7.35 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -7.35    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -93.29%   |   Position Changes : 43   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=4900, episode_reward=-2.70 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 1199     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -93.80%   |   Position Changes : 56   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5000, episode_reward=-2.78 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.78    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.04%   |   Position Changes : 130   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5100, episode_reward=-4.64 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -4.64    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 1249     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -98.79%   |   Position Changes : 191   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5200, episode_reward=-4.42 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -4.42    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 1274     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -89.06%   |   Position Changes : 72   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5300, episode_reward=-2.21 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.21    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 1299     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.26%   |   Position Changes : 83   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5400, episode_reward=-3.60 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 1324     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -95.04%   |   Position Changes : 60   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5500, episode_reward=-3.00 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000964 |\n",
      "|    n_updates        | 1349     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -90.52%   |   Position Changes : 36   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5600, episode_reward=-2.36 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.36    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -92.64%   |   Position Changes : 37   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5700, episode_reward=-2.61 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.61    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000969 |\n",
      "|    n_updates        | 1399     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.32%   |   Position Changes : 61   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5800, episode_reward=-3.62 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.62    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 1424     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.94%   |   Position Changes : 128   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=5900, episode_reward=-2.98 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.98    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 1449     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -98.44%   |   Position Changes : 81   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6000, episode_reward=-4.16 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -4.16    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -96.20%   |   Position Changes : 88   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6100, episode_reward=-3.27 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.27    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 1499     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -86.36%   |   Position Changes : 41   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6200, episode_reward=-1.99 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -1.99    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000743 |\n",
      "|    n_updates        | 1524     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -95.51%   |   Position Changes : 59   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6300, episode_reward=-3.10 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 1549     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -93.43%   |   Position Changes : 75   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6400, episode_reward=-2.72 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.72    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 1574     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -93.21%   |   Position Changes : 50   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6500, episode_reward=-2.69 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.69    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 1599     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -94.00%   |   Position Changes : 49   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6600, episode_reward=-2.81 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.81    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 1624     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -90.20%   |   Position Changes : 44   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6700, episode_reward=-2.32 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.32    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 1649     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.06%   |   Position Changes : 93   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6800, episode_reward=-4.67 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -4.67    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 1674     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -95.48%   |   Position Changes : 65   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=6900, episode_reward=-3.10 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 1699     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -86.52%   |   Position Changes : 25   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7000, episode_reward=-2.00 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 1724     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -89.07%   |   Position Changes : 34   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7100, episode_reward=-2.21 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.21    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 1749     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 646   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7200, episode_reward=-10.07 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -10.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -95.82%   |   Position Changes : 72   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7300, episode_reward=-3.17 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.17    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 1799     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.87%   |   Position Changes : 274   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7400, episode_reward=-6.63 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -6.63    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 1824     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.97%   |   Position Changes : 482   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7500, episode_reward=-8.25 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -8.25    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 1849     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.74%   |   Position Changes : 152   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7600, episode_reward=-3.79 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.79    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000815 |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -97.80%   |   Position Changes : 95   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7700, episode_reward=-3.82 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.82    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 1899     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -98.55%   |   Position Changes : 119   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7800, episode_reward=-4.23 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -4.23    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 1924     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 6336   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=7900, episode_reward=-45.48 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -45.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 1949     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 13157   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8000, episode_reward=-91.10 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -91.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 11005   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8100, episode_reward=-79.00 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -79      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 1999     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.73%   |   Position Changes : 137   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8200, episode_reward=-5.90 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -5.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 2024     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -93.30%   |   Position Changes : 42   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8300, episode_reward=-2.70 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 2049     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -89.26%   |   Position Changes : 34   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8400, episode_reward=-2.23 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.23    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 2074     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -96.70%   |   Position Changes : 43   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8500, episode_reward=-3.41 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.41    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 2099     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.47%   |   Position Changes : 194   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8600, episode_reward=-5.24 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -5.24    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 2124     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.99%   |   Position Changes : 520   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8700, episode_reward=-8.92 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -8.92    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 2149     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.85%   |   Position Changes : 409   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8800, episode_reward=-6.53 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -6.53    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 2174     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.86%   |   Position Changes : 268   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=8900, episode_reward=-6.59 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -6.59    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 2199     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 2355   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9000, episode_reward=-22.13 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -22.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 2224     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 1405   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9100, episode_reward=-13.32 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -13.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 2871   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9200, episode_reward=-25.07 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -25.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 2274     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 1509   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9300, episode_reward=-15.41 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -15.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9300     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000901 |\n",
      "|    n_updates        | 2299     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 5490   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9400, episode_reward=-42.18 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -42.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 2324     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.61%   |   Position Changes : 245   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9500, episode_reward=-5.54 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -5.54    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 2349     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -98.35%   |   Position Changes : 186   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9600, episode_reward=-4.10 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -4.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -92.39%   |   Position Changes : 56   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9700, episode_reward=-2.58 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -2.58    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000826 |\n",
      "|    n_updates        | 2399     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -96.77%   |   Position Changes : 164   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9800, episode_reward=-3.43 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -3.43    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 2424     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -99.39%   |   Position Changes : 186   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=9900, episode_reward=-5.10 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -5.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 2449     |\n",
      "----------------------------------\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 23230   |   Episode Length : 25746   |   \n",
      "Eval num_timesteps=10000, episode_reward=-155.29 +/- 0.00\n",
      "Episode length: 25745.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.57e+04 |\n",
      "|    mean_reward      | -155     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      " * Serving Flask app 'gym_trading_env.renderer'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "coin_data = preprocess(data)\n",
    "env.reset()\n",
    "\n",
    "model = DQN('MlpPolicy', env, learning_starts=100, verbose=1, tau=0.9, exploration_initial_eps=0.5, exploration_fraction=0.1, exploration_final_eps=0.05, device='cpu')\n",
    "\n",
    "# Wrap the environment with Monitor\n",
    "eval_env = Monitor(env)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env, best_model_save_path='./logs/',\n",
    "    log_path='./logs/', eval_freq=100,\n",
    "    n_eval_episodes=1,\n",
    "    deterministic=True, render=False\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=1e4, callback=eval_callback)\n",
    "\n",
    "env.render()\n",
    "\n",
    "env.unwrapped.save_for_render()\n",
    "renderer = Renderer(render_logs_dir=\"render_logs/BTC\")\n",
    "renderer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 4, 'step': 0, 'date': numpy.datetime64('2021-01-03T15:00:00.000000000'), 'position_index': 7, 'position': -0.25, 'real_position': -0.25, 'data_high': 33873.45, 'data_open': 33811.54, 'data_volume': 8391.249757, 'data_close': 33506.62, 'data_low': 32727.0, 'portfolio_valuation': 1000.0, 'portfolio_distribution_asset': 0, 'portfolio_distribution_fiat': 1250.0, 'portfolio_distribution_borrowed_asset': 0.0074612121425557095, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 0, 'portfolio_distribution_interest_fiat': 0, 'reward': 0}\n",
      "Market Return : 23.01%   |   Portfolio Return : -100.00%   |   Position Changes : 17424   |   Episode Length : 25746   |   \n",
      "{'idx': 25749, 'step': 25745, 'date': numpy.datetime64('2023-12-12T22:00:00.000000000'), 'position_index': array(1), 'position': -4, 'real_position': -4.055608217957823, 'data_high': 41220.38, 'data_open': 41104.02, 'data_volume': 665.07274, 'data_close': 41216.95, 'data_low': 41079.48, 'portfolio_valuation': 6.779153500117447e-17, 'portfolio_distribution_asset': 0, 'portfolio_distribution_fiat': 3.4272744145991304e-16, 'portfolio_distribution_borrowed_asset': 6.670437323807163e-21, 'portfolio_distribution_borrowed_fiat': 0, 'portfolio_distribution_interest_asset': 2.0011311971421485e-26, 'portfolio_distribution_interest_fiat': 0.0, 'reward': -0.01405824037172421}\n",
      " * Serving Flask app 'gym_trading_env.renderer'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [13/Dec/2023 00:14:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Dec/2023 00:14:46] \"GET /update_data/USD_2023-12-13_00-14-40.pkl HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Dec/2023 00:14:47] \"GET /metrics HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "model = DQN.load(\"logs/best_model.zip\")\n",
    "\n",
    "done, truncated = False, False\n",
    "observation, info = env.reset()\n",
    "print(info)\n",
    "while not done and not truncated:\n",
    "    action, _ = model.predict(observation)\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    if done or truncated:\n",
    "        print(info)\n",
    "\n",
    "env.render()\n",
    "env.unwrapped.save_for_render()\n",
    "\n",
    "renderer = Renderer(render_logs_dir=\"render_logs/BTC\")\n",
    "renderer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitcoinbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
